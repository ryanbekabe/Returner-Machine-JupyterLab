{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/snowflakes-fractal-using-python/\n",
    "# Python code to draw snowflakes fractal. \n",
    "import turtle \n",
    "import random \n",
    "\n",
    "# setup the window with a background color \n",
    "wn = turtle.Screen() \n",
    "wn.bgcolor(\"cyan\") \n",
    "\n",
    "# assign a name to your turtle \n",
    "elsa = turtle.Turtle() \n",
    "elsa.speed(15) \n",
    "\n",
    "# create a list of colours \n",
    "sfcolor = [\"white\", \"blue\", \"purple\", \"grey\", \"magenta\"] \n",
    "\n",
    "# create a function to create different size snowflakes \n",
    "def snowflake(size): \n",
    "\n",
    "\t# move the pen into starting position \n",
    "\telsa.penup() \n",
    "\telsa.forward(10*size) \n",
    "\telsa.left(45) \n",
    "\telsa.pendown() \n",
    "\telsa.color(random.choice(sfcolor)) \n",
    "\n",
    "\t# draw branch 8 times to make a snowflake \n",
    "\tfor i in range(8): \n",
    "\t\tbranch(size) \n",
    "\t\telsa.left(45) \n",
    "\t\n",
    "\n",
    "# create one branch of the snowflake \n",
    "def branch(size): \n",
    "\tfor i in range(3): \n",
    "\t\tfor i in range(3): \n",
    "\t\t\telsa.forward(10.0*size/3) \n",
    "\t\t\telsa.backward(10.0*size/3) \n",
    "\t\t\telsa.right(45) \n",
    "\t\telsa.left(90) \n",
    "\t\telsa.backward(10.0*size/3) \n",
    "\t\telsa.left(45) \n",
    "\telsa.right(90) \n",
    "\telsa.forward(10.0*size) \n",
    "\n",
    "# loop to create 20 different sized snowflakes \n",
    "# with different starting co-ordinates \n",
    "for i in range(20): \n",
    "\tx = random.randint(-200, 200) \n",
    "\ty = random.randint(-200, 200) \n",
    "\tsf_size = random.randint(1, 4) \n",
    "\telsa.penup() \n",
    "\telsa.goto(x, y) \n",
    "\telsa.pendown() \n",
    "\tsnowflake(sf_size) \n",
    "\n",
    "# leave the window open until you click to close \n",
    "wn.exitonclick() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python-sierpinski-carpet/\n",
    "# importing necessary modules \n",
    "import numpy as np \n",
    "from PIL import Image \n",
    "\n",
    "# total number of times the process will be repeated \n",
    "total = 7\n",
    "\n",
    "# size of the image \n",
    "size = 3**total \n",
    "\n",
    "# creating an image \n",
    "square = np.empty([size, size, 3], dtype = np.uint8) \n",
    "color = np.array([255, 255, 255], dtype = np.uint8) \n",
    "\n",
    "# filling it black \n",
    "square.fill(0) \n",
    "\n",
    "for i in range(0, total + 1): \n",
    "\tstepdown = 3**(total - i) \n",
    "\tfor x in range(0, 3**i): \n",
    "\t\t\n",
    "\t\t# checking for the centremost square \n",
    "\t\tif x % 3 == 1: \n",
    "\t\t\tfor y in range(0, 3**i): \n",
    "\t\t\t\tif y % 3 == 1: \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t# changing its color \n",
    "\t\t\t\t\tsquare[y * stepdown:(y + 1)*stepdown, x * stepdown:(x + 1)*stepdown] = color \n",
    "\n",
    "# saving the image produced \n",
    "save_file = \"sierpinski.jpg\"\n",
    "Image.fromarray(square).save(save_file) \n",
    "\n",
    "# displaying it in console \n",
    "i = Image.open(\"sierpinski.jpg\") \n",
    "i.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8d36fafba0c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[0mzy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmoveY\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxIter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                         \u001b[1;32mwhile\u001b[0m \u001b[0mzx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mzy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzy\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                                 \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mzy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzy\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                 \u001b[0mzy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mzx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzy\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Python code for Julia Fractal \n",
    "from PIL import Image \n",
    "\n",
    "# driver function \n",
    "if __name__ == \"__main__\": \n",
    "\t\n",
    "\t# setting the width, height and zoom \n",
    "\t# of the image to be created \n",
    "\tw, h, zoom = 1920,1080,1\n",
    "\n",
    "\t# creating the new image in RGB mode \n",
    "\tbitmap = Image.new(\"RGB\", (w, h), \"white\") \n",
    "\n",
    "\t# Allocating the storage for the image and \n",
    "\t# loading the pixel data. \n",
    "\tpix = bitmap.load() \n",
    "\t\n",
    "\t# setting up the variables according to \n",
    "\t# the equation to create the fractal \n",
    "\tcX, cY = -0.7, 0.27015\n",
    "\tmoveX, moveY = 0.0, 0.0\n",
    "\tmaxIter = 255\n",
    "\n",
    "\tfor x in range(w): \n",
    "\t\tfor y in range(h): \n",
    "\t\t\tzx = 1.5*(x - w/2)/(0.5*zoom*w) + moveX \n",
    "\t\t\tzy = 1.0*(y - h/2)/(0.5*zoom*h) + moveY \n",
    "\t\t\ti = maxIter \n",
    "\t\t\twhile zx*zx + zy*zy < 4 and i > 1: \n",
    "\t\t\t\ttmp = zx*zx - zy*zy + cX \n",
    "\t\t\t\tzy,zx = 2.0*zx*zy + cY, tmp \n",
    "\t\t\t\ti -= 1\n",
    "\n",
    "\t\t\t# convert byte to RGB (3 bytes), kinda \n",
    "\t\t\t# magic to get nice colors \n",
    "\t\t\tpix[x,y] = (i << 21) + (i << 10) + i*8\n",
    "\n",
    "\t# to display the created fractal \n",
    "\tbitmap.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter iteration: 4\n",
      "Enter length of each segment: 4\n",
      "Enter pen color: 4\n",
      "Enter background color: 4\n",
      "Display r/l form?(y/n): y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rrlrrllrrrllrll\n"
     ]
    },
    {
     "ename": "Terminator",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminator\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fe514445d4db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# for not show the turtle icon when drawing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mturtle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mht\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0mturtle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mturtle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpencolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\turtle.py\u001b[0m in \u001b[0;36mht\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTerminator\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the turtle module to use turtle graphics \n",
    "import turtle \n",
    "\n",
    "# make variables for the right and left containing 'r' and 'l' \n",
    "r = 'r'\n",
    "l = 'l'\n",
    "\n",
    "# assign our first iteration a right so we can build off of it \n",
    "old = r \n",
    "new = old \n",
    "\n",
    "# for inputs \n",
    "iteration = int(input('Enter iteration:')) \n",
    "length = int(input('Enter length of each segment:')) \n",
    "pencolor = input('Enter pen color:') \n",
    "bgcolor = input('Enter background color:') \n",
    "\n",
    "# set the number of times we have been creating \n",
    "# the next iteration as the first \n",
    "cycle = 1\n",
    "\n",
    "# keep on generating the next iteration until desired iteration is reached \n",
    "while cycle<iteration: \n",
    "\t# add a right to the end of the old iteration and save it to the new \n",
    "\tnew = (old) + (r) \n",
    "\t# flip the old iteration around(as in the first charicter becomes last) \n",
    "\told = old[::-1] \n",
    "\t# cycling through each character in the flipped old iteration: \n",
    "\tfor char in range(0, len(old)): \n",
    "\t\t# if the character is a right: \n",
    "\t\tif old[char] == r: \n",
    "\t\t\t# change it to a left \n",
    "\t\t\told = (old[:char])+ (l) + (old[char + 1:]) \n",
    "\t\t# otherwise, if it's a left: \n",
    "\t\telif old[char] == l: \n",
    "\t\t\t#change it to a right \n",
    "\t\t\told = (old[:char]) + (r) + (old[char + 1:]) \n",
    "\t# add the modified old to the new iteration \n",
    "\tnew = (new) + (old) \n",
    "\n",
    "\t# save the new iteration to old as well for use next cycle \n",
    "\told = new \n",
    "\n",
    "\t# advance cycle variable to keep track of the number of times it's been done \n",
    "\tcycle = cycle + 1\n",
    "\n",
    "\n",
    "printans = input('Display r/l form?(y/n):') \n",
    "if printans =='y': \n",
    "\tprint(new) \n",
    "\t\n",
    "# for not show the turtle icon when drawing \n",
    "turtle.ht() \n",
    "turtle.speed(0) \n",
    "turtle.color(pencolor) \n",
    "turtle.bgcolor(bgcolor) \n",
    "turtle.forward(length) \n",
    "\n",
    "# cycling through all the characters in the iteration \n",
    "for char in range(0, len(new)): \n",
    "\t# if the character is a right: \n",
    "\tif new[char] == (r): \n",
    "\t\tturtle.right(90) \n",
    "\t\tturtle.forward(length) \n",
    "\t# otherwise, if the character is a left: \n",
    "\telif new[char] == (l):\t \n",
    "\t\tturtle.left(90) \n",
    "\t\tturtle.forward(length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b6c88a100bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnumba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\site-packages\\numba\\cuda\\api.py\u001b[0m in \u001b[0;36mselect_device\u001b[1;34m(device_id)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mRaises\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mon\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36mget_context\u001b[1;34m(devnum)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \"\"\"\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36mget_or_create_context\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mattached_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activate_context_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_or_create_context_uncached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36m_activate_context_for\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_activate_context_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mgpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mnewctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_primary_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;31m# Detect unexpected context switch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         '''\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)\n",
    "numba.cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
      " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
      "  144. 144. 144. 144. 144. 144. 144. 144.]]\n"
     ]
    }
   ],
   "source": [
    "#https://nyu-cds.github.io/python-numba/05-cuda/\n",
    "from __future__ import division\n",
    "from numba import cuda\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "# CUDA kernel\n",
    "@cuda.jit\n",
    "def matmul(A, B, C):\n",
    "    \"\"\"Perform matrix multiplication of C = A * B\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)\n",
    "    if row < C.shape[0] and col < C.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(A.shape[1]):\n",
    "            tmp += A[row, k] * B[k, col]\n",
    "        C[row, col] = tmp\n",
    "        \n",
    "# Host code\n",
    "\n",
    "# Initialize the data arrays\n",
    "A = numpy.full((24, 12), 3, numpy.float) # matrix containing all 3's\n",
    "B = numpy.full((12, 22), 4, numpy.float) # matrix containing all 4's\n",
    "\n",
    "# Copy the arrays to the device\n",
    "A_global_mem = cuda.to_device(A)\n",
    "B_global_mem = cuda.to_device(B)\n",
    "\n",
    "# Allocate memory on the device for the result\n",
    "C_global_mem = cuda.device_array((24, 22))\n",
    "\n",
    "# Configure the blocks\n",
    "threadsperblock = (16, 16)\n",
    "blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n",
    "blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "# Start the kernel \n",
    "matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
    "\n",
    "# Copy the result back to the host\n",
    "C = C_global_mem.copy_to_host()\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mat1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bc6a7b1f6349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTPB\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTPB\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [48 x 16] matrix containing all 4's\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mA_global_mem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mB_global_mem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mC_global_mem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTPB\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTPB\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [32 x 16] matrix result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mat1' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from numba import cuda, float32\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "# Controls threads per block and shared memory usage.\n",
    "# The computation will be done on blocks of TPBxTPB elements.\n",
    "TPB = 16\n",
    "\n",
    "@cuda.jit\n",
    "def fast_matmul(A, B, C):\n",
    "    \"\"\"\n",
    "    Perform matrix multiplication of C = A * B\n",
    "    Each thread computes one element of the result matrix C\n",
    "    \"\"\"\n",
    "\n",
    "    # Define an array in the shared memory\n",
    "    # The size and type of the arrays must be known at compile time\n",
    "    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n",
    "\n",
    "    x, y = cuda.grid(2)\n",
    "    \n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    \n",
    "    if x >= C.shape[0] and y >= C.shape[1]:\n",
    "        # Quit if (x, y) is outside of valid C boundary\n",
    "        return\n",
    "\n",
    "    # Each thread computes one element in the result matrix.\n",
    "    # The dot product is chunked into dot products of TPB-long vectors.\n",
    "    tmp = 0.\n",
    "    for i in range(int(A.shape[1] / TPB)):\n",
    "        # Preload data into shared memory\n",
    "        sA[tx, ty] = A[x, ty + i * TPB]\n",
    "        sB[tx, ty] = B[tx + i * TPB, y]\n",
    "\n",
    "        # Wait until all threads finish preloading\n",
    "        cuda.syncthreads()\n",
    "\n",
    "        # Computes partial product on the shared memory\n",
    "        for j in range(TPB):\n",
    "            tmp += sA[tx, j] * sB[j, ty]\n",
    "\n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()\n",
    "\n",
    "    C[x, y] = tmp\n",
    "\n",
    "# The data array\n",
    "A = numpy.full((TPB*2, TPB*3), 3, numpy.float) # [32 x 48] matrix containing all 3's\n",
    "B = numpy.full((TPB*3, TPB*1), 4, numpy.float) # [48 x 16] matrix containing all 4's\n",
    "\n",
    "A_global_mem = cuda.to_device(mat1)\n",
    "B_global_mem = cuda.to_device(mat2)\n",
    "C_global_mem = cuda.device_array((TPB*2, TPB*1)) # [32 x 16] matrix result\n",
    "\n",
    "# Configure the blocks\n",
    "threadsperblock = (TPB, TPB)\n",
    "blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[1]))\n",
    "blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[0]))\n",
    "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "\n",
    "# Start the kernel \n",
    "fast_matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
    "res = C_global_mem.copy_to_host()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5 ms ± 768 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "#https://thedatafrog.com/en/make-python-fast-numba/\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "import math\n",
    "\n",
    "def std(xs):\n",
    "  # compute the mean\n",
    "  mean = 0\n",
    "  for x in xs: \n",
    "    mean += x\n",
    "  mean /= len(xs)\n",
    "  # compute the variance\n",
    "  ms = 0\n",
    "  for x in xs:\n",
    "     ms += (x-mean)**2\n",
    "  variance = ms / len(xs)\n",
    "  std = math.sqrt(variance)\n",
    "  return std\n",
    "\n",
    "a = np.random.normal(0, 1, 10000000)\n",
    "#std(a)\n",
    "#%timeit std(a)\n",
    "##13.9 s ± 566 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "##1.000286796167372\n",
    "\n",
    "c_std = njit(std)\n",
    "c_std(a)\n",
    "%timeit c_std(a)\n",
    "##40.8 ms ± 340 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19688451  0.95178969  0.41837853 ...,  0.75325694  0.50432418\n",
      "  0.67023501]\n",
      "[ 0.19688451  0.95178969  0.41837853 ...,  0.75325694  0.50432418\n",
      "  0.67023501]\n",
      "1.55 ms ± 121 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "3.14472\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import random\n",
    "import numpy as np\n",
    "x = np.random.random(1_000_000)\n",
    "y = np.random.random(1_000_000)\n",
    "print(x)\n",
    "print(x)\n",
    "\n",
    "def mcp0(x, y):\n",
    "   acc = np.sum(x ** 2 + y ** 2 < 1)\n",
    "   return 4 * acc / len(x)\n",
    "\n",
    "#%timeit mcp0(x, y)\n",
    "#print(mcp0(x, y))\n",
    "\n",
    "@numba.jit\n",
    "def mcp(x, y):\n",
    "   acc = np.sum(x ** 2 + y ** 2 < 1)\n",
    "   return 4 * acc / len(x)\n",
    "\n",
    "%timeit mcp(x, y)\n",
    "#32.9 ms ± 576 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) -> CPU\n",
    "#1.69 ms ± 47.6 µs per loop (mean ± std. dev. of 7 runs, 1 loop each) -> GPU\n",
    "\n",
    "print(mcp(x, y))\n",
    "#3.1412520000000002 -> CPU \n",
    "#3.141308 -> GPU\n",
    "#3.141468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n",
      "[ 0.54330889]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#from numpy.random import default_rng\n",
    "#from numpy.random import Generator, PCG64\n",
    "#rng = np.random.default_rng()\n",
    "#rng.permutation(10)\n",
    "\n",
    "numre = np.arange(100).reshape((10, 10))\n",
    "#numre = np.arange(25).reshape((5, 5))\n",
    "#numre = np.arange(9).reshape((3, 3))\n",
    "rng = np.random.random(1)\n",
    "print(numre)\n",
    "print(rng)\n",
    "\n",
    "#print(np.permutation(rng))\n",
    "#rng = np.random.default_rng()\n",
    "#rng.permutation(10)\n",
    "#arr = np.arange(9).reshape((3, 3))\n",
    "#rng.permutation(arr)\n",
    "#array([[6, 7, 8], # random\n",
    "#       [0, 1, 2],\n",
    "#       [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 3.  4.]]\n",
      "[[ 5.  6.]\n",
      " [ 7.  5.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  5.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from numpy import *\n",
    "import numpy as np\n",
    "#A = np.random.random(4) #matrix('1.0 2.0; 3.0 4.0')\n",
    "#B = np.random.random(4)\n",
    "A = np.matrix('1.0 2.0; 3.0 4.0')\n",
    "B = np.matrix('5.0 6.0; 7.0 5.0')\n",
    "print(A)\n",
    "print(B)\n",
    "np.concatenate((A, B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrices\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[7 8]]\n",
      "Vertical Combine\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Horizontal Combine\n",
      "[[1 2 3 7 8]\n",
      " [4 5 6 0 0]]\n",
      "Diagonal Combine\n",
      "[[1 2 3 0 0]\n",
      " [4 5 6 0 0]\n",
      " [0 0 0 7 8]]\n"
     ]
    }
   ],
   "source": [
    "# Advanced combining\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "A = np.matrix('1 2 3; 4 5 6')\n",
    "B = np.matrix('7 8')\n",
    "print('Original Matrices')\n",
    "print(A)\n",
    "print(B)\n",
    "\n",
    "# Getting the size\n",
    "shA=np.shape(A)\n",
    "shB=np.shape(B)\n",
    "rowTot=shA[0]+shB[0]\n",
    "colTot=shA[1]+shB[1]\n",
    "rowMax=np.max((shA[0],shB[0]))\n",
    "colMax=np.max((shA[1],shB[1]))\n",
    "\n",
    "# Allocate zeros to C\n",
    "CVert=np.zeros((rowTot,colMax)).astype('int')\n",
    "CHorz=np.zeros((rowMax,colTot)).astype('int')\n",
    "CDiag=np.zeros((rowTot,colTot)).astype('int')\n",
    "\n",
    "# Replace C\n",
    "CVert[0:shA[0],0:shA[1]]=A\n",
    "CVert[shA[0]:rowTot,0:shB[1]]=B\n",
    "print('Vertical Combine')\n",
    "print(CVert)\n",
    "\n",
    "CHorz[0:shA[0],0:shA[1]]=A\n",
    "CHorz[0:shB[0],shA[1]:colTot]=B\n",
    "print('Horizontal Combine')\n",
    "print(CHorz)\n",
    "\n",
    "CDiag[0:shA[0],0:shA[1]]=A\n",
    "CDiag[shA[0]:rowTot,shA[1]:colTot]=B\n",
    "print('Diagonal Combine')\n",
    "print(CDiag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.7 ms ± 3.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import math\n",
    "import numba as nb\n",
    "import timeit\n",
    "\n",
    "LOOKUP_TABLE = np.array([\n",
    "    1, 1, 2, 6, 24, 120, 720, 5040, 40320,\n",
    "    362880, 3628800, 39916800, 479001600,\n",
    "    6227020800, 87178291200, 1307674368000,\n",
    "    20922789888000, 355687428096000, 6402373705728000,\n",
    "    121645100408832000, 2432902008176640000], dtype='int64')\n",
    "\n",
    "@nb.jit\n",
    "def fast_factorial(n):\n",
    "    if n > 20:\n",
    "        raise ValueError\n",
    "    return LOOKUP_TABLE[n]\n",
    "\n",
    "def loop_python():\n",
    "    for i in range(10000):\n",
    "        for n in range(21):\n",
    "            math.factorial(n)\n",
    "\n",
    "@nb.njit\n",
    "def loop_numba():\n",
    "    for i in range(10000):\n",
    "        for n in range(21):\n",
    "            fast_factorial(n)\n",
    "\n",
    "#%timeit math.factorial(10)\n",
    "#%timeit fast_factorial(10)\n",
    "\n",
    "%timeit loop_python()\n",
    "#%timeit loop_numba()\n",
    "\n",
    "#273 ns ± 52.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
    "#3.3 µs ± 1.74 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "#87.7 ms ± 3.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "#The slowest run took 11.25 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
    "#1.07 µs ± 1.41 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "\n",
    "#Kernel Kaggle\n",
    "#38.6 ms ± 705 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "#The slowest run took 6.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
    "#759 ns ± 786 ns per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class '_frozen_importlib._ModuleLockManager'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\asus\\appdata\\local\\audio-visualizer-screenlet\\miniconda\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <class '_frozen_importlib._ModuleLockManager'> returned a result with an error set"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import timeit\n",
    "import math\n",
    "#import numba as nb\n",
    "import timeit\n",
    "#import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "LOOKUP_TABLE = np.array([\n",
    "    1, 1, 2, 6, 24, 120, 720, 5040, 40320,\n",
    "    362880, 3628800, 39916800, 479001600,\n",
    "    6227020800, 87178291200, 1307674368000,\n",
    "    20922789888000, 355687428096000, 6402373705728000,\n",
    "    121645100408832000, 2432902008176640000], dtype='int64')\n",
    "\n",
    "#@nb.jit\n",
    "def fast_factorial(n):\n",
    "    if n > 20:\n",
    "        raise ValueError\n",
    "    return LOOKUP_TABLE[n]\n",
    "\n",
    "def loop_python():\n",
    "    for i in range(10000):\n",
    "        for n in range(21):\n",
    "            math.factorial(n)\n",
    "\n",
    "#@nb.njit\n",
    "def loop_numba():\n",
    "    for i in range(10000):\n",
    "        for n in range(21):\n",
    "            fast_factorial(n)\n",
    "\n",
    "#%timeit math.factorial(10)\n",
    "#%timeit fast_factorial(10)\n",
    "\n",
    "#%timeit loop_python()\n",
    "#loop_numba()\n",
    "\n",
    "print('bismillah...')\n",
    "print('Num GPUs Available:  ', len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b09588a16cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num GPUs Available: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 19.00 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "800 ns ± 1.23 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Bismillah\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import math\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "LOOKUP_TABLE = np.array([\n",
    "    1, 1, 2, 6, 24, 120, 720, 5040, 40320,\n",
    "    362880, 3628800, 39916800, 479001600,\n",
    "    6227020800, 87178291200, 1307674368000,\n",
    "    20922789888000, 355687428096000, 6402373705728000,\n",
    "    121645100408832000, 2432902008176640000], dtype='int64')\n",
    "\n",
    "@nb.jit\n",
    "def fast_factorial(n):\n",
    "    if n > 20:\n",
    "        raise ValueError\n",
    "    return LOOKUP_TABLE[n]\n",
    "\n",
    "def loop_python():\n",
    "    for i in range(10000):\n",
    "        for n in range(21):\n",
    "            math.factorial(n)\n",
    "\n",
    "@nb.njit\n",
    "def loop_numba():\n",
    "    for i in range(10001):\n",
    "        for n in range(21):\n",
    "            fast_factorial(n)\n",
    "\n",
    "#%timeit math.factorial(10)\n",
    "#%timeit fast_factorial(10)\n",
    "\n",
    "#%timeit loop_python()\n",
    "%timeit loop_numba()\n",
    "\n",
    "#273 ns ± 52.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
    "#3.3 µs ± 1.74 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "#87.7 ms ± 3.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "#The slowest run took 11.25 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
    "#1.07 µs ± 1.41 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "\n",
    "#Kernel Kaggle\n",
    "#38.6 ms ± 705 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "#The slowest run took 6.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
    "#759 ns ± 786 ns per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "print('Bismillah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   9.   10.   11.   12.   13.   14.   15.   16.   17.   18.]\n",
      " [  19.   20.   21.   22.   23.   24.   25.   26.   27.   28.]\n",
      " [  29.   30.   31.   32.   33.   34.   35.   36.   37.   38.]\n",
      " [  39.   40.   41.   42.   43.   44.   45.   46.   47.   48.]\n",
      " [  49.   50.   51.   52.   53.   54.   55.   56.   57.   58.]\n",
      " [  59.   60.   61.   62.   63.   64.   65.   66.   67.   68.]\n",
      " [  69.   70.   71.   72.   73.   74.   75.   76.   77.   78.]\n",
      " [  79.   80.   81.   82.   83.   84.   85.   86.   87.   88.]\n",
      " [  89.   90.   91.   92.   93.   94.   95.   96.   97.   98.]\n",
      " [  99.  100.  101.  102.  103.  104.  105.  106.  107.  108.]]\n"
     ]
    }
   ],
   "source": [
    "#https://numba.pydata.org/numba-doc/dev/user/5minguide.html\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "    return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "print(go_fast(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (with compilation) = 0.5176949501037598\n",
      "Elapsed (after compilation) = 0.0\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a): # Function is compiled and runs in machine code\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
